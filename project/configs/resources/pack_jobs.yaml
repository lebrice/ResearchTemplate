# @package _global_
defaults:
  - override /hydra/launcher: custom_submitit_slurm
trainer:
  accelerator: gpu
  devices: 1
hydra:
  mode: MULTIRUN
  launcher:
    cpus_per_task: 2
    nodes: 1
    # TODO: Packing more than one job on a single GPU seems to be working, but both tasks get the
    # same job parameters.
    tasks_per_node: 2
    mem_gb: 16
    array_parallelism: 16  # max num of jobs to run in parallel
    gres: gpu:1
    # Other things to pass to `sbatch`:
    additional_parameters:
      time: 1-00:00:00  # maximum wall time allocated for the job (D-HH:MM:SS)

    ## A list of commands to add to the generated sbatch script before running srun:
    setup:
    - unset CUDA_VISIBLE_DEVICES
    # - export CUDA_VISIBLE_DEVICES="0"
    # - export LD_PRELOAD=/some/folder/with/libraries/
