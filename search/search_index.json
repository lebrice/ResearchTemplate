{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Research Project Template","text":"<p>Please note: This is a Work-in-Progress. The goal is to make a first release by the end of summer 2024.</p> <p>This is a research project template. It is meant to be a starting point for ML researchers at Mila.</p> <p>For more context, see this  introduction to the project..</p>"},{"location":"#overview","title":"Overview","text":"<p>This project makes use of the following libraries:</p> <ul> <li>Hydra is used to configure the project. It allows you to define configuration files and override them from the command line.</li> <li>PyTorch Lightning is used to as the training framework. It provides a high-level interface to organize ML research code.<ul> <li>\ud83d\udd25 Please note: You can also use Jax with this repo, as is shown in the Jax example \ud83d\udd25</li> </ul> </li> <li>Weights &amp; Biases is used to log metrics and visualize results.</li> <li>pytest is used for testing.</li> </ul>"},{"location":"#usage","title":"Usage","text":"<p>To see all available options:</p> <pre><code>python project/main.py --help\n</code></pre> <p>For a detailed list of examples, see the examples page.</p>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>pyproject.toml   # Project metadata and dependencies\nproject/\n    main.py      # main entry-point\n    algorithms/  # learning algorithms\n    datamodules/ # datasets, processing and loading\n    networks/    # Neural networks used by algorithms\n    configs/     # configuration files\ndocs/            # documentation\nconftest.py      # Test fixtures and utilities\n</code></pre>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>Overview<ul> <li>overview/*.md</li> </ul> </li> <li>Getting Started<ul> <li>getting_started/*.md</li> </ul> </li> <li>Reference<ul> <li>reference/*</li> </ul> </li> <li>Examples<ul> <li>examples/*</li> </ul> </li> <li>Tests</li> <li>Related projects</li> <li>Getting Help</li> <li>Contributing</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>TODOs:</p> <ul> <li>[ ] Describe how to contribute to the project.</li> </ul>"},{"location":"help/","title":"Help and Support","text":""},{"location":"help/#faq","title":"FAQ","text":""},{"location":"help/#how-to-get-help","title":"How to get help","text":""},{"location":"related/","title":"Related projects and resources","text":"<p>There are other very similar projects with significantly better documentation. In all cases that involve Hydra and PyTorch-Lightning, this documentation also applies directly to this project, so in order to avoid copying their documentation, here are some links:</p> <ul> <li> <p>lightning-hydra-template</p> <ul> <li>How it works: https://github.com/gorodnitskiy/yet-another-lightning-hydra-template/tree/main?tab=readme-ov-file#workflow---how-it-works</li> </ul> </li> <li> <p>yet-another-lightning-hydra-template</p> <ul> <li>Excellent template.  based on the lightning-hydra-template. Great documentation, which is referenced extensively in this project.</li> <li> <ul> <li>Has a great Readme with lots of information</li> </ul> </li> <li> <ul> <li>Is really well organized</li> </ul> </li> <li> <ul> <li>doesn't support Jax</li> </ul> </li> <li> <ul> <li>doesn't have a devcontainer</li> </ul> </li> <li>Great blog: https://hackernoon.com/yet-another-lightning-hydra-template-for-ml-experiments</li> </ul> </li> <li> <p>cookiecutter-data-science</p> <ul> <li>Awesome library for data science.</li> <li>Related projects: https://github.com/drivendataorg/cookiecutter-data-science/blob/master/docs/docs/related.md#links-to-related-projects-and-references</li> </ul> </li> </ul>"},{"location":"tests/","title":"Tests","text":"<p>TODOs:</p> <ul> <li>[ ] Described what is tested by the included automated tests (a bit like what is done here)</li> <li>[ ] Add some examples of how to run tests</li> <li>[ ] describe why the test files are next to the source files, and why TDD is good, and why ML researchers should care more about tests.</li> <li>[ ] Explain how the fixtures in <code>conftest.py</code> work (indirect parametrization of the command-line overrides, etc).</li> <li>[ ] Describe the Github Actions workflows that come with the template, and how to setup a self-hosted runner for template forks.</li> <li>[ ] Add links to relevant documentation ()</li> </ul>"},{"location":"examples/examples/","title":"Examples","text":"<p>TODOs:</p> <ul> <li>[ ] Show examples (that are also to be tested with doctest or similar) of how to add a new algo.</li> <li>[ ] Show examples of how to add a new datamodule.</li> <li>[ ] Add a link to the RL example once #13 is done.</li> <li>[ ] Add a link to the NLP example once #14 is done.</li> <li>[ ] Add an example of how to use Jax for the dataset/dataloading:<ul> <li>Either through an RL example, or with <code>tfds</code> in #18</li> </ul> </li> </ul>"},{"location":"examples/examples/#simple-run","title":"Simple run","text":"<pre><code>python project/main.py algorithm=example datamodule=mnist network=fcnet\n</code></pre>"},{"location":"examples/examples/#running-a-hyper-parameter-sweep-on-a-slurm-cluster","title":"Running a Hyper-Parameter sweep on a SLURM cluster","text":"<pre><code>python project/main.py experiment=cluster_sweep_example\n</code></pre>"},{"location":"examples/jax/","title":"Using Jax","text":"<p>You can use Jax for your dataloading, your network, or the learning algorithm, all while still benefiting from the nice stuff that comes from using PyTorch-Lightning.</p> <p>How does this work? Well, we use torch-jax-interop, another package developed here at Mila, which allows easy interop between torch and jax code. See the readme on that repo for more details.</p>"},{"location":"examples/jax/#example-algorithm-that-uses-jax","title":"Example Algorithm that uses Jax","text":"<p>You can use Jax for your training step, but not the entire training loop (since that is handled by Lightning). There are a few good reasons why you should let Lightning handle the training loop, most notably the fact that it handles all the logging, checkpointing, and other stuff that you'd lose if you swapped out the entire training framework for something based on Jax.</p> <p>In this example Jax algorithm, a Neural network written in Jax (using flax) is wrapped using the <code>torch_jax_interop.JaxFunction</code>, so that its parameters are learnable. The parameters are saved on the LightningModule as nn.Parameters (which use the same underlying memory as the jax arrays). In this example, the loss function is written in PyTorch, while the network forward and backward passes are written in Jax.</p>"},{"location":"examples/jax/#example-datamodule-that-uses-jax","title":"Example datamodule that uses Jax","text":"<p>(todo)</p>"},{"location":"getting_started/install/","title":"Installation instructions","text":"<p>There are two ways to install this project</p> <ol> <li>Using Conda (recommended for newcomers)</li> <li>Using a development container (recommended if you are able to install Docker on your machine)</li> </ol>"},{"location":"getting_started/install/#using-conda-and-pip","title":"Using Conda and pip","text":""},{"location":"getting_started/install/#prerequisites","title":"Prerequisites","text":"<p>You need to have Conda installed on your machine.</p>"},{"location":"getting_started/install/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository and navigate to the root directory:</p> <pre><code>git clone https://www.github.com/mila-iqia/ResearchTemplate\ncd ResearchTemplate\n</code></pre> </li> <li> <p>Create a conda environment</p> <pre><code>conda create -n research_template python=3.12\nconda activate research_template\n</code></pre> <p>Notes:</p> <ul> <li>If you don't Conda installed, you can download it from here.</li> <li>If you'd rather use a virtual environment instead of Conda, you can totally do so, as long as you have a version of Python &gt;= 3.12.</li> </ul> </li> <li> <p>Install the package using pip:</p> <pre><code>pip install -e .\n</code></pre> <p>Optionally, you can also install the package using PDM. This makes it easier to add or change the dependencies later on:</p> <pre><code>pip install pdm\npdm install\n</code></pre> </li> </ol>"},{"location":"getting_started/install/#using-a-development-container","title":"Using a development container","text":"<p>This repo provides a Devcontainer configuration for Visual Studio Code to use a Docker container as a pre-configured development environment. This avoids struggles setting up a development environment and makes them reproducible and consistent.  and make yourself familiar with the container tutorials if you want to use them. In order to use GPUs, you can enable them within the <code>.devcontainer/devcontainer.json</code> file.</p> <ol> <li> <p>Setup Docker on your local machine</p> <p>On an Linux machine where you have root access, you can install Docker using the following commands:</p> <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre> <p>On Windows or Mac, follow these installation instructions</p> </li> <li> <p>(optional) Install the nvidia-container-toolkit to use your local machine's GPU(s).</p> </li> <li> <p>Install the Dev Containers extension for Visual Studio Code.</p> </li> <li> <p>When opening repository in Visual Studio Code, you should be prompted to reopen the repository in a container:</p> <p></p> <p>Alternatively, you can open the command palette (Ctrl+Shift+P) and select <code>Dev Containers: Rebuild and Reopen in Container</code>.</p> </li> </ol>"},{"location":"overview/intro/","title":"Introduction","text":""},{"location":"overview/intro/#why-should-you-use-this-template","title":"Why should you use this template?","text":""},{"location":"overview/intro/#why-should-you-use-a-template-in-the-first-place","title":"Why should you use a template in the first place?","text":"<p>For many good reasons, which are very well described here in a similar project! \ud83d\ude0a</p> <p>Other good reads:</p> <ul> <li>https://cookiecutter-data-science.drivendata.org/why/</li> <li>https://cookiecutter-data-science.drivendata.org/opinions/</li> <li>https://12factor.net/</li> <li>https://github.com/ashleve/lightning-hydra-template/tree/main?tab=readme-ov-file#main-ideas</li> </ul>"},{"location":"overview/intro/#why-should-you-use-this-template-instead-of-another","title":"Why should you use this template (instead of another)?","text":"<p>You are welcome (and encouraged) to use other similar templates which, at the time of writing this, have significantly better documentation. However, there are several advantages to using this particular template:</p> <ul> <li>\u2757Support for both Jax and Torch with PyTorch-Lightning \u2757</li> <li>Easy development inside a devcontainer with VsCode</li> <li>Tailor-made for ML researchers that run their jobs on SLURM clusters (with default configurations for the Mila and DRAC clusters.)</li> <li>Rich typing of all parts of the source code using Python 3.12's new type annotation syntax</li> <li>A comprehensive suite of automated tests for new algorithms, datasets and networks</li> <li>Automatically creates Yaml Schemas for your Hydra config files (as soon as #7 is merged)</li> </ul> <p>This template is aimed for ML researchers that run their jobs on SLURM clusters. The target audience is researchers and students at Mila. This template should still be useful for others outside of Mila that use PyTorch-Lightning and Hydra.</p>"},{"location":"overview/intro/#main-concepts","title":"Main concepts","text":""},{"location":"overview/intro/#datamodule","title":"Datamodule","text":""},{"location":"overview/intro/#network","title":"Network","text":""},{"location":"overview/intro/#algorithm","title":"Algorithm","text":""},{"location":"reference/project/conftest/","title":"Conftest","text":"<p>Fixtures and test utilities.</p> <p>This module contains PyTest fixtures that are used by tests.</p>"},{"location":"reference/project/conftest/#project.conftest.seed","title":"seed","text":"<pre><code>seed(\n    request: FixtureRequest, make_torch_deterministic: None\n)\n</code></pre> <p>Fixture that seeds everything for reproducibility and yields the random seed used.</p>"},{"location":"reference/project/conftest/#project.conftest.accelerator","title":"accelerator","text":"<pre><code>accelerator(request: FixtureRequest)\n</code></pre> <p>Returns the accelerator to use during unit tests.</p> <p>By default, if cuda is available, returns \"cuda\". If the tests are run with -vvv, then also runs CPU.</p>"},{"location":"reference/project/conftest/#project.conftest.devices","title":"devices","text":"<pre><code>devices(\n    accelerator: str, num_devices_to_use: int\n) -&gt; list[int] | int\n</code></pre> <p>Fixture that creates the 'devices' argument for the Trainer config.</p>"},{"location":"reference/project/conftest/#project.conftest.overrides","title":"overrides","text":"<pre><code>overrides(request: FixtureRequest)\n</code></pre> <p>Fixture that makes it possible to specify command-line overrides to use in a given test.</p> <p>Tests that require running an experiment should use the <code>experiment_config</code> fixture below.</p> <p>Multiple test using the same overrides will use the same experiment.</p>"},{"location":"reference/project/conftest/#project.conftest.use_overrides","title":"use_overrides","text":"<pre><code>use_overrides(\n    command_line_overrides: Param | list[Param], ids=None\n)\n</code></pre> <p>Marks a test so that it can use components created using the given command-line arguments.</p> <p>For example:</p> <pre><code>@use_overrides(\"algorithm=my_algo network=fcnet\")\ndef test_my_algo(algorithm: MyAlgorithm):\n    #The algorithm will be setup the same as if we did\n    #   `python main.py algorithm=my_algo network=fcnet`.\n    ...\n</code></pre>"},{"location":"reference/project/conftest/#project.conftest.algorithm_config","title":"algorithm_config","text":"<pre><code>algorithm_config(request: FixtureRequest) -&gt; str | None\n</code></pre> <p>The name of the config to use within the \"algorithm\" group.</p>"},{"location":"reference/project/conftest/#project.conftest.datamodule_config","title":"datamodule_config","text":"<pre><code>datamodule_config(request: FixtureRequest) -&gt; str | None\n</code></pre> <p>The name of the config to use within the \"datamodule\" group.</p>"},{"location":"reference/project/conftest/#project.conftest.common_setup_experiment_part","title":"common_setup_experiment_part","text":"<pre><code>common_setup_experiment_part(experiment_config: Config)\n</code></pre> <p>Fixture that is used to run the common part of <code>setup_experiment</code>.</p> <p>This is there so that we can instantiate only one or a few of the experiment components (e.g. only the Network), while also only doing the common part once if we were to use more than one of these components and their associated fixtures below.</p>"},{"location":"reference/project/conftest/#project.conftest.num_classes","title":"num_classes","text":"<pre><code>num_classes(datamodule: DataModule) -&gt; int\n</code></pre> <p>Returns a batch of data from the training set of an image classification datamodule.</p>"},{"location":"reference/project/conftest/#project.conftest.algorithm","title":"algorithm","text":"<pre><code>algorithm(\n    experiment_config: Config,\n    datamodule: DataModule,\n    network: Module,\n)\n</code></pre> <p>Fixture that creates an \"algorithm\" (LightningModule).</p>"},{"location":"reference/project/conftest/#project.conftest.make_torch_deterministic","title":"make_torch_deterministic","text":"<pre><code>make_torch_deterministic()\n</code></pre> <p>Set torch to deterministic mode for unit tests that use the tensor_regression fixture.</p>"},{"location":"reference/project/conftest/#project.conftest.pytest_runtest_makereport","title":"pytest_runtest_makereport","text":"<pre><code>pytest_runtest_makereport(item, call)\n</code></pre> <p>Used to setup the <code>pytest.mark.incremental</code> mark, as described in this page.</p>"},{"location":"reference/project/conftest/#project.conftest.pytest_runtest_setup","title":"pytest_runtest_setup","text":"<pre><code>pytest_runtest_setup(item)\n</code></pre> <p>Used to setup the <code>pytest.mark.incremental</code> mark, as described in this page.</p>"},{"location":"reference/project/conftest/#project.conftest.pytest_generate_tests","title":"pytest_generate_tests","text":"<pre><code>pytest_generate_tests(metafunc: Metafunc) -&gt; None\n</code></pre> <p>Allows one to define custom parametrization schemes or extensions.</p> <p>This is used to implement the <code>parametrize_when_used</code> mark, which allows one to parametrize an argument when it is used.</p> <p>See https://docs.pytest.org/en/7.1.x/how-to/parametrize.html#how-to-parametrize-fixtures-and-test-functions</p>"},{"location":"reference/project/experiment/","title":"Experiment","text":""},{"location":"reference/project/experiment/#project.experiment.Experiment","title":"Experiment  <code>dataclass</code>","text":"<p>Dataclass containing everything used in an experiment.</p> <p>This gets created from the config that are parsed from Hydra. Can be used to run the experiment by calling <code>run(experiment)</code>. Could also be serialized to a file or saved to disk, which might come in handy with <code>submitit</code> later on.</p>"},{"location":"reference/project/experiment/#project.experiment.setup_experiment","title":"setup_experiment","text":"<pre><code>setup_experiment(experiment_config: Config) -&gt; Experiment\n</code></pre> <p>Do all the postprocessing necessary (e.g., create the network, datamodule, callbacks, Trainer, Algorithm, etc) to go from the options that come from Hydra, into all required components for the experiment, which is stored as a dataclass called <code>Experiment</code>.</p> <p>NOTE: This also has the effect of seeding the random number generators, so the weights that are constructed are deterministic and reproducible.</p>"},{"location":"reference/project/experiment/#project.experiment.instantiate_network","title":"instantiate_network","text":"<pre><code>instantiate_network(\n    experiment_config: Config, datamodule: DataModule\n) -&gt; Module\n</code></pre> <p>Create the network given the configs.</p>"},{"location":"reference/project/experiment/#project.experiment.instantiate_network_from_hparams","title":"instantiate_network_from_hparams","text":"<pre><code>instantiate_network_from_hparams(\n    network_hparams: Dataclass, datamodule: DataModule\n) -&gt; Module\n</code></pre> <p>TODO: Refactor this if possible. Shouldn't be as complicated as it currently is.</p> <p>Perhaps we could register handler functions for each pair of datamodule and network type, a bit like a multiple dispatch?</p>"},{"location":"reference/project/main/","title":"Main","text":"<p>Main entry-point.</p>"},{"location":"reference/project/main/#project.main.main","title":"main","text":"<pre><code>main(dict_config: DictConfig) -&gt; dict\n</code></pre> <p>Main entry point for training a model.</p>"},{"location":"reference/project/main/#project.main.evaluation","title":"evaluation","text":"<pre><code>evaluation(\n    experiment: Experiment,\n) -&gt; tuple[str, float | None, dict]\n</code></pre> <p>Return the classification error.</p> <p>By default, if validation is to be performed, returns the validation error. Returns the training error when <code>trainer.overfit_batches != 0</code> (e.g. when debugging or testing). Otherwise, if <code>trainer.limit_val_batches == 0</code>, returns the test error.</p>"},{"location":"reference/project/algorithms/example/","title":"Example","text":"<p>Example of an algorithm, which is a Pytorch Lightning image classifier.</p> <p>Uses regular backpropagation.</p>"},{"location":"reference/project/algorithms/example/#project.algorithms.example.ExampleAlgorithm","title":"ExampleAlgorithm","text":"<p>               Bases: <code>LightningModule</code></p> <p>Example learning algorithm for image classification.</p>"},{"location":"reference/project/algorithms/example/#project.algorithms.example.ExampleAlgorithm.device","title":"device  <code>property</code>","text":"<pre><code>device: device\n</code></pre> <p>Small fixup for the <code>device</code> property in LightningModule, which is CPU by default.</p>"},{"location":"reference/project/algorithms/example/#project.algorithms.example.ExampleAlgorithm.__init__","title":"__init__","text":"<pre><code>__init__(\n    datamodule: ImageClassificationDataModule,\n    network: Module,\n    optimizer_config: Any = AdamConfig(lr=0.0003),\n)\n</code></pre> <p>Create a new instance of the algorithm.</p>"},{"location":"reference/project/algorithms/example/#project.algorithms.example.ExampleAlgorithm.__init__--parameters","title":"Parameters","text":"<p>datamodule: Object used to load train/val/test data. See the lightning docs for the             <code>LightningDataModule</code> class more info. network: The network to train. optimizer_config: Configuration options for the Optimizer.</p>"},{"location":"reference/project/algorithms/jax_example/","title":"Jax example","text":""},{"location":"reference/project/algorithms/jax_example/#project.algorithms.jax_example.CNN","title":"CNN","text":"<p>               Bases: <code>Module</code></p> <p>A simple CNN model.</p> <p>Taken from https://flax.readthedocs.io/en/latest/quick_start.html#define-network</p>"},{"location":"reference/project/algorithms/jax_example/#project.algorithms.jax_example.JaxExample","title":"JaxExample","text":"<p>               Bases: <code>LightningModule</code></p> <p>Example of a learning algorithm (<code>LightningModule</code>) that uses Jax.</p> <p>In this case, the network is a flax.linen.Module, and its forward and backward passes are written in Jax, and the loss function is in pytorch.</p>"},{"location":"reference/project/algorithms/jax_example/#project.algorithms.jax_example.JaxExample.device","title":"device  <code>property</code>","text":"<pre><code>device: device\n</code></pre> <p>Small fixup for the <code>device</code> property in LightningModule, which is CPU by default.</p>"},{"location":"reference/project/algorithms/jax_example/#project.algorithms.jax_example.JaxExample.HParams","title":"HParams  <code>dataclass</code>","text":"<p>Hyper-parameters of the algo.</p>"},{"location":"reference/project/algorithms/jax_example/#project.algorithms.jax_example.jit","title":"jit","text":"<pre><code>jit(fn: Callable[P, Out]) -&gt; Callable[P, Out]\n</code></pre> <p>Small type hint fix for jax's <code>jit</code> (preserves the signature of the callable).</p>"},{"location":"reference/project/algorithms/jax_example/#project.algorithms.jax_example.value_and_grad","title":"value_and_grad","text":"<pre><code>value_and_grad(\n    fn: Callable[Concatenate[In, P], tuple[Out, Aux]],\n    argnums: Literal[0] = 0,\n    has_aux: Literal[True] = True,\n) -&gt; Callable[\n    Concatenate[In, P], tuple[tuple[Out, Aux], In]\n]\n</code></pre> <p>Small type hint fix for jax's <code>value_and_grad</code> (preserves the signature of the callable).</p>"},{"location":"reference/project/algorithms/no_op/","title":"No op","text":""},{"location":"reference/project/algorithms/no_op/#project.algorithms.no_op.NoOp","title":"NoOp","text":"<p>               Bases: <code>LightningModule</code></p> <p>No-op algorithm that does no learning and is used to benchmark the dataloading speed.</p>"},{"location":"reference/project/algorithms/callbacks/callback/","title":"Callback","text":""},{"location":"reference/project/algorithms/callbacks/callback/#project.algorithms.callbacks.callback.Callback","title":"Callback","text":"<p>               Bases: <code>Callback</code>, <code>Generic[BatchType, StepOutputType]</code></p> <p>Adds a bit of typing info and shared functions to the PyTorch Lightning Callback class.</p> <p>Adds the following typing information: - The type of inputs that the algorithm takes - The type of outputs that are returned by the algorithm's <code>[training/validation/test]_step</code> methods.</p> <p>Adds the following methods: - <code>on_shared_batch_start</code>: called by <code>on_[train/validation/test]_batch_start</code> - <code>on_shared_batch_end</code>: called by <code>on_[train/validation/test]_batch_end</code> - <code>on_shared_epoch_start</code>: called by <code>on_[train/validation/test]_epoch_start</code> - <code>on_shared_epoch_end</code>: called by <code>on_[train/validation/test]_epoch_end</code></p>"},{"location":"reference/project/algorithms/callbacks/callback/#project.algorithms.callbacks.callback.Callback.on_shared_batch_start","title":"on_shared_batch_start","text":"<pre><code>on_shared_batch_start(\n    trainer: Trainer,\n    pl_module: LightningModule,\n    batch: BatchType,\n    batch_index: int,\n    phase: Literal[\"train\", \"val\", \"test\"],\n    dataloader_idx: int | None = None,\n)\n</code></pre> <p>Shared hook, called by <code>on_[train/validation/test]_batch_start</code>.</p> <p>Use this if you want to do something at the start of batches in more than one phase.</p>"},{"location":"reference/project/algorithms/callbacks/callback/#project.algorithms.callbacks.callback.Callback.on_shared_batch_end","title":"on_shared_batch_end","text":"<pre><code>on_shared_batch_end(\n    trainer: Trainer,\n    pl_module: LightningModule,\n    outputs: StepOutputType,\n    batch: BatchType,\n    batch_index: int,\n    phase: Literal[\"train\", \"val\", \"test\"],\n    dataloader_idx: int | None = None,\n)\n</code></pre> <p>Shared hook, called by <code>on_[train/validation/test]_batch_end</code>.</p> <p>Use this if you want to do something at the end of batches in more than one phase.</p>"},{"location":"reference/project/algorithms/callbacks/callback/#project.algorithms.callbacks.callback.Callback.on_shared_epoch_start","title":"on_shared_epoch_start","text":"<pre><code>on_shared_epoch_start(\n    trainer: Trainer,\n    pl_module: LightningModule,\n    phase: Literal[\"train\", \"val\", \"test\"],\n) -&gt; None\n</code></pre> <p>Shared hook, called by <code>on_[train/validation/test]_epoch_start</code>.</p> <p>Use this if you want to do something at the start of epochs in more than one phase.</p>"},{"location":"reference/project/algorithms/callbacks/callback/#project.algorithms.callbacks.callback.Callback.on_shared_epoch_end","title":"on_shared_epoch_end","text":"<pre><code>on_shared_epoch_end(\n    trainer: Trainer,\n    pl_module: LightningModule,\n    phase: Literal[\"train\", \"val\", \"test\"],\n) -&gt; None\n</code></pre> <p>Shared hook, called by <code>on_[train/validation/test]_epoch_end</code>.</p> <p>Use this if you want to do something at the end of epochs in more than one phase.</p>"},{"location":"reference/project/algorithms/callbacks/classification_metrics/","title":"Classification metrics","text":""},{"location":"reference/project/algorithms/callbacks/classification_metrics/#project.algorithms.callbacks.classification_metrics.ClassificationOutputs","title":"ClassificationOutputs","text":"<p>               Bases: <code>TypedDict</code></p> <p>The outputs that should be minimally returned from the training/val/test_step of classification LightningModules so that metrics can be added aumatically by the <code>ClassificationMetricsCallback</code>.</p>"},{"location":"reference/project/algorithms/callbacks/classification_metrics/#project.algorithms.callbacks.classification_metrics.ClassificationOutputs.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss: NotRequired[Tensor | float]\n</code></pre> <p>The loss at this step.</p>"},{"location":"reference/project/algorithms/callbacks/classification_metrics/#project.algorithms.callbacks.classification_metrics.ClassificationOutputs.logits","title":"logits  <code>instance-attribute</code>","text":"<pre><code>logits: Required[Tensor]\n</code></pre> <p>The un-normalized logits.</p>"},{"location":"reference/project/algorithms/callbacks/classification_metrics/#project.algorithms.callbacks.classification_metrics.ClassificationOutputs.y","title":"y  <code>instance-attribute</code>","text":"<pre><code>y: Required[Tensor]\n</code></pre> <p>The class labels.</p>"},{"location":"reference/project/algorithms/callbacks/classification_metrics/#project.algorithms.callbacks.classification_metrics.ClassificationMetricsCallback","title":"ClassificationMetricsCallback","text":"<p>               Bases: <code>Callback[BatchType, ClassificationOutputs]</code></p> <p>Callback that adds classification metrics to a LightningModule.</p>"},{"location":"reference/project/algorithms/callbacks/samples_per_second/","title":"Samples per second","text":""},{"location":"reference/project/algorithms/testsuites/algorithm/","title":"Algorithm","text":""},{"location":"reference/project/algorithms/testsuites/algorithm/#project.algorithms.testsuites.algorithm.StepOutputDict","title":"StepOutputDict","text":"<p>               Bases: <code>TypedDict</code></p> <p>A dictionary that shows what an Algorithm can output from <code>training/validation/test_step</code>.</p>"},{"location":"reference/project/algorithms/testsuites/algorithm/#project.algorithms.testsuites.algorithm.StepOutputDict.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss: NotRequired[Tensor | float]\n</code></pre> <p>Optional loss tensor that can be returned by those methods.</p>"},{"location":"reference/project/algorithms/testsuites/algorithm/#project.algorithms.testsuites.algorithm.Algorithm","title":"Algorithm","text":"<p>               Bases: <code>Module</code>, <code>Protocol[BatchType, StepOutputType]</code></p> <p>Protocol that adds more type information to the <code>lightning.LightningModule</code> class.</p> <p>This adds some type information on top of the LightningModule class, namely: - <code>BatchType</code>: The type of batch that is produced by the dataloaders of the datamodule - <code>StepOutputType</code>, the output type created by the step methods.</p> <p>The networks themselves are created separately and passed as a constructor argument. This is meant to make it easier to compare different learning algorithms on the same network architecture.</p>"},{"location":"reference/project/algorithms/testsuites/algorithm_tests/","title":"Algorithm tests","text":""},{"location":"reference/project/algorithms/testsuites/algorithm_tests/#project.algorithms.testsuites.algorithm_tests.LearningAlgorithmTests","title":"LearningAlgorithmTests","text":"<p>               Bases: <code>Generic[AlgorithmType]</code>, <code>ABC</code></p> <p>Suite of unit tests for an \"Algorithm\" (LightningModule).</p>"},{"location":"reference/project/algorithms/testsuites/algorithm_tests/#project.algorithms.testsuites.algorithm_tests.LearningAlgorithmTests.forward_pass_input","title":"forward_pass_input","text":"<pre><code>forward_pass_input(training_batch: PyTree[Tensor])\n</code></pre> <p>Extracts the model input from a batch of data coming from the dataloader.</p> <p>Overwrite this if your batches are not tuples of tensors (i.e. if your algorithm isn't a simple supervised learning algorithm like the example).</p>"},{"location":"reference/project/algorithms/testsuites/algorithm_tests/#project.algorithms.testsuites.algorithm_tests.LearningAlgorithmTests.test_backward_pass_is_deterministic","title":"test_backward_pass_is_deterministic","text":"<pre><code>test_backward_pass_is_deterministic(\n    datamodule: LightningDataModule,\n    algorithm: LightningModule,\n    seed: int,\n    accelerator: str,\n    devices: int | list[int],\n    tmp_path: Path,\n)\n</code></pre> <p>Check that the backward pass is reproducible given the same input, weights, and random seed.</p>"},{"location":"reference/project/algorithms/testsuites/algorithm_tests/#project.algorithms.testsuites.algorithm_tests.LearningAlgorithmTests.test_initialization_is_reproducible","title":"test_initialization_is_reproducible","text":"<pre><code>test_initialization_is_reproducible(\n    experiment_config: Config,\n    datamodule: DataModule,\n    network: Module,\n    seed: int,\n    tensor_regression: TensorRegressionFixture,\n)\n</code></pre> <p>Check that the network initialization is reproducible given the same random seed.</p>"},{"location":"reference/project/algorithms/testsuites/algorithm_tests/#project.algorithms.testsuites.algorithm_tests.LearningAlgorithmTests.test_forward_pass_is_reproducible","title":"test_forward_pass_is_reproducible","text":"<pre><code>test_forward_pass_is_reproducible(\n    forward_pass_input: Any,\n    algorithm: LightningModule,\n    seed: int,\n    tensor_regression: TensorRegressionFixture,\n)\n</code></pre> <p>Check that the forward pass is reproducible given the same input and random seed.</p>"},{"location":"reference/project/configs/config/","title":"Config","text":""},{"location":"reference/project/configs/config/#project.configs.config.Config","title":"Config  <code>dataclass</code>","text":"<p>All the options required for a run. This dataclass acts as a schema for the Hydra configs.</p> <p>For more info, see https://hydra.cc/docs/tutorials/structured_config/schema/</p>"},{"location":"reference/project/configs/config/#project.configs.config.Config.datamodule","title":"datamodule  <code>instance-attribute</code>","text":"<pre><code>datamodule: Any\n</code></pre> <p>Configuration for the datamodule (dataset + transforms + dataloader creation).</p>"},{"location":"reference/project/configs/config/#project.configs.config.Config.algorithm","title":"algorithm  <code>instance-attribute</code>","text":"<pre><code>algorithm: Any\n</code></pre> <p>The hyper-parameters of the algorithm to use.</p>"},{"location":"reference/project/configs/config/#project.configs.config.Config.network","title":"network  <code>instance-attribute</code>","text":"<pre><code>network: Any\n</code></pre> <p>The network to use.</p>"},{"location":"reference/project/configs/config/#project.configs.config.Config.trainer","title":"trainer  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>trainer: dict = field(default_factory=dict)\n</code></pre> <p>Keyword arguments for the Trainer constructor.</p>"},{"location":"reference/project/configs/config/#project.configs.config.Config.log_level","title":"log_level  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>log_level: str = 'info'\n</code></pre> <p>Logging level.</p>"},{"location":"reference/project/configs/config/#project.configs.config.Config.seed","title":"seed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>seed: int | None = field(\n    default_factory=lambda: randint(0, int(100000.0))\n)\n</code></pre> <p>Random seed for reproducibility.</p> <p>If None, a random seed is generated.</p>"},{"location":"reference/project/datamodules/vision/","title":"Vision","text":""},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule","title":"VisionDataModule","text":"<p>               Bases: <code>LightningDataModule</code>, <code>DataModule[BatchType_co]</code></p> <p>A LightningDataModule for image datasets.</p> <p>(Taken from pl_bolts which is not very well maintained.)</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.name","title":"name  <code>class-attribute</code>","text":"<pre><code>name: str = ''\n</code></pre> <p>Dataset name.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.dataset_cls","title":"dataset_cls  <code>class-attribute</code>","text":"<pre><code>dataset_cls: type[VisionDataset]\n</code></pre> <p>Dataset class to use.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.dims","title":"dims  <code>class-attribute</code>","text":"<pre><code>dims: tuple[C, H, W]\n</code></pre> <p>A tuple describing the shape of the data.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.__init__","title":"__init__","text":"<pre><code>__init__(\n    data_dir: str | Path = DATA_DIR,\n    val_split: int | float = 0.2,\n    num_workers: int = NUM_WORKERS,\n    normalize: bool = False,\n    batch_size: int = 32,\n    seed: int = 42,\n    shuffle: bool = True,\n    pin_memory: bool = True,\n    drop_last: bool = False,\n    train_transforms: Callable | None = None,\n    val_transforms: Callable | None = None,\n    test_transforms: Callable | None = None,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str | Path</code> <p>Where to save/load the data</p> <code>DATA_DIR</code> <code>val_split</code> <code>int | float</code> <p>Percent (float) or number (int) of samples to use for the validation split</p> <code>0.2</code> <code>num_workers</code> <code>int</code> <p>How many workers to use for loading data</p> <code>NUM_WORKERS</code> <code>normalize</code> <code>bool</code> <p>If true applies image normalize</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>How many samples per batch to load</p> <code>32</code> <code>seed</code> <code>int</code> <p>Random seed to be used for train/val/test splits</p> <code>42</code> <code>shuffle</code> <code>bool</code> <p>If true shuffles the train data every epoch</p> <code>True</code> <code>pin_memory</code> <code>bool</code> <p>If true, the data loader will copy Tensors into CUDA pinned memory before         returning them</p> <code>True</code> <code>drop_last</code> <code>bool</code> <p>If true drops the last incomplete batch</p> <code>False</code> <code>train_transforms</code> <code>Callable | None</code> <p>transformations you can apply to train dataset</p> <code>None</code> <code>val_transforms</code> <code>Callable | None</code> <p>transformations you can apply to validation dataset</p> <code>None</code> <code>test_transforms</code> <code>Callable | None</code> <p>transformations you can apply to test dataset</p> <code>None</code>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.prepare_data","title":"prepare_data","text":"<pre><code>prepare_data() -&gt; None\n</code></pre> <p>Saves files to data_dir.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.default_transforms","title":"default_transforms  <code>abstractmethod</code>","text":"<pre><code>default_transforms() -&gt; Callable\n</code></pre> <p>Default transform for the dataset.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.train_dataloader","title":"train_dataloader","text":"<pre><code>train_dataloader(\n    _dataloader_fn: Callable[\n        Concatenate[Dataset, P], DataLoader\n    ] = DataLoader,\n    *args: args,\n    **kwargs: kwargs\n) -&gt; DataLoader\n</code></pre> <p>The train dataloader.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.val_dataloader","title":"val_dataloader","text":"<pre><code>val_dataloader(\n    _dataloader_fn: Callable[\n        Concatenate[Dataset, P], DataLoader\n    ] = DataLoader,\n    *args: args,\n    **kwargs: kwargs\n) -&gt; DataLoader\n</code></pre> <p>The val dataloader.</p>"},{"location":"reference/project/datamodules/vision/#project.datamodules.vision.VisionDataModule.test_dataloader","title":"test_dataloader","text":"<pre><code>test_dataloader(\n    _dataloader_fn: Callable[\n        Concatenate[Dataset, P], DataLoader\n    ] = DataLoader,\n    *args: args,\n    **kwargs: kwargs\n) -&gt; DataLoader\n</code></pre> <p>The test dataloader.</p>"},{"location":"reference/project/datamodules/image_classification/cifar10/","title":"Cifar10","text":""},{"location":"reference/project/datamodules/image_classification/cifar10/#project.datamodules.image_classification.cifar10.CIFAR10DataModule","title":"CIFAR10DataModule","text":"<p>               Bases: <code>ImageClassificationDataModule</code>, <code>VisionDataModule</code></p> <p>.. figure:: https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/     Plot-of-a-Subset-of-Images-from-the-CIFAR-10-Dataset.png     :width: 400     :alt: CIFAR-10</p> Specs <ul> <li>10 classes (1 per class)</li> <li>Each image is (3 x 32 x 32)</li> </ul> <p>Standard CIFAR10, train, val, test splits and transforms</p> <p>Transforms::</p> <pre><code>transforms = transform_lib.Compose([\n    transform_lib.ToImage(),\n    transform_lib.ToDtype(torch.float32, scale=True),\n    transform_lib.Normalize(\n        mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n        std=[x / 255.0 for x in [63.0, 62.1, 66.7]]\n    )\n])\n</code></pre> <p>Example::</p> <pre><code>from pl_bolts.datamodules import CIFAR10DataModule\n\ndm = CIFAR10DataModule(PATH)\nmodel = LitModel()\n\nTrainer().fit(model, datamodule=dm)\n</code></pre> <p>Or you can set your own transforms</p> <p>Example::</p> <pre><code>dm.train_transforms = ...\ndm.test_transforms = ...\ndm.val_transforms  = ...\n</code></pre>"},{"location":"reference/project/datamodules/image_classification/fashion_mnist/","title":"Fashion mnist","text":""},{"location":"reference/project/datamodules/image_classification/fashion_mnist/#project.datamodules.image_classification.fashion_mnist.FashionMNISTDataModule","title":"FashionMNISTDataModule","text":"<p>               Bases: <code>MNISTDataModule</code></p> <p>.. figure:: https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/     wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-Fashion-MNIST-Dataset.png     :width: 400     :alt: Fashion MNIST</p> Specs <ul> <li>10 classes (1 per type)</li> <li>Each image is (1 x 28 x 28)</li> </ul> <p>Standard FashionMNIST, train, val, test splits and transforms</p> <p>Transforms::</p> <pre><code>mnist_transforms = transform_lib.Compose([\n    transform_lib.ToTensor()\n])\n</code></pre> <p>Example::</p> <pre><code>from pl_bolts.datamodules import FashionMNISTDataModule\n\ndm = FashionMNISTDataModule('.')\nmodel = LitModel()\n\nTrainer().fit(model, datamodule=dm)\n</code></pre>"},{"location":"reference/project/datamodules/image_classification/image_classification/","title":"Image classification","text":""},{"location":"reference/project/datamodules/image_classification/image_classification/#project.datamodules.image_classification.image_classification.ImageClassificationDataModule","title":"ImageClassificationDataModule","text":"<p>               Bases: <code>VisionDataModule[BatchType]</code>, <code>ClassificationDataModule[BatchType]</code></p> <p>Lightning data modules for image classification.</p>"},{"location":"reference/project/datamodules/image_classification/image_classification/#project.datamodules.image_classification.image_classification.ImageClassificationDataModule.num_classes","title":"num_classes  <code>instance-attribute</code>","text":"<pre><code>num_classes: int\n</code></pre> <p>Number of classes in the dataset.</p>"},{"location":"reference/project/datamodules/image_classification/image_classification/#project.datamodules.image_classification.image_classification.ImageClassificationDataModule.dims","title":"dims  <code>instance-attribute</code>","text":"<pre><code>dims: tuple[C, H, W]\n</code></pre> <p>A tuple describing the shape of the data.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/","title":"Imagenet","text":""},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule","title":"ImageNetDataModule","text":"<p>               Bases: <code>VisionDataModule</code></p> <p>ImageNet datamodule.</p> <p>Extracted from https://github.com/Lightning-Universe/lightning-bolts/blob/master/src/pl_bolts/datamodules/imagenet_datamodule.py - Made this a subclass of VisionDataModule</p> <p>Notes: - train_dataloader uses the train split of imagenet2012 and puts away a portion of it for the validation split. - val_dataloader uses the part of the train split of imagenet2012  that was not used for training via     <code>num_imgs_per_val_class</code>     - TODO: needs to pass split='val' to UnlabeledImagenet. - test_dataloader uses the validation split of imagenet2012 for testing.     - TODO: need to pass num_imgs_per_class=-1 for test dataset and split=\"test\".</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.name","title":"name  <code>class-attribute</code>","text":"<pre><code>name: str = 'imagenet'\n</code></pre> <p>Dataset name.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.dataset_cls","title":"dataset_cls  <code>class-attribute</code>","text":"<pre><code>dataset_cls: type[ImageNet] = ImageNet\n</code></pre> <p>Dataset class to use.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.dims","title":"dims  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dims: tuple[C, H, W] = (\n    C(3),\n    H(image_size),\n    W(image_size),\n)\n</code></pre> <p>A tuple describing the shape of the data.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.__init__","title":"__init__","text":"<pre><code>__init__(\n    data_dir: str | Path = DATA_DIR,\n    *,\n    val_split: int | float = 0.01,\n    num_workers: int = NUM_WORKERS,\n    normalize: bool = False,\n    image_size: int = 224,\n    batch_size: int = 32,\n    seed: int = 42,\n    shuffle: bool = True,\n    pin_memory: bool = True,\n    drop_last: bool = False,\n    train_transforms: Callable | None = None,\n    val_transforms: Callable | None = None,\n    test_transforms: Callable | None = None,\n    **kwargs\n)\n</code></pre> <p>Creates an ImageNet datamodule (doesn't load or prepare the dataset yet).</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.__init__--parameters","title":"Parameters","text":"<p>data_dir: path to the imagenet dataset file val_split: save <code>val_split</code>% of the training data of each class for validation. image_size: final image size num_workers: how many data workers batch_size: batch_size shuffle: If true shuffles the data every epoch pin_memory: If true, the data loader will copy Tensors into CUDA pinned memory before                     returning them drop_last: If true drops the last incomplete batch</p>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.train_transform","title":"train_transform","text":"<pre><code>train_transform() -&gt; Module[[Tensor], Tensor]\n</code></pre> <p>The standard imagenet transforms.</p> <p>.. code-block:: python</p> <pre><code>transform_lib.Compose([\n    transform_lib.RandomResizedCrop(self.image_size),\n    transform_lib.RandomHorizontalFlip(),\n    transform_lib.ToTensor(),\n    transform_lib.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ),\n])\n</code></pre>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.ImageNetDataModule.val_transform","title":"val_transform","text":"<pre><code>val_transform() -&gt; Callable\n</code></pre> <p>The standard imagenet transforms for validation.</p> <p>.. code-block:: python</p> <pre><code>transform_lib.Compose([\n    transform_lib.Resize(self.image_size + 32),\n    transform_lib.CenterCrop(self.image_size),\n    transform_lib.ToTensor(),\n    transform_lib.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ),\n])\n</code></pre>"},{"location":"reference/project/datamodules/image_classification/imagenet/#project.datamodules.image_classification.imagenet.prepare_imagenet","title":"prepare_imagenet","text":"<pre><code>prepare_imagenet(\n    root: Path,\n    *,\n    split: Literal[\"train\", \"val\"] = \"train\",\n    network_imagenet_dir: Path\n) -&gt; None\n</code></pre> <p>Custom preparation function for ImageNet, using @obilaniu's tar magic in Python form.</p> <p>The core of this is equivalent to these bash commands:</p> <pre><code>mkdir -p $SLURM_TMPDIR/imagenet/val\ncd       $SLURM_TMPDIR/imagenet/val\ntar  -xf /network/scratch/b/bilaniuo/ILSVRC2012_img_val.tar\nmkdir -p $SLURM_TMPDIR/imagenet/train\ncd       $SLURM_TMPDIR/imagenet/train\ntar  -xf /network/datasets/imagenet/ILSVRC2012_img_train.tar          --to-command='mkdir ${TAR_REALNAME%.tar}; tar -xC ${TAR_REALNAME%.tar}'\n</code></pre>"},{"location":"reference/project/datamodules/image_classification/imagenet32/","title":"Imagenet32","text":""},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32Dataset","title":"ImageNet32Dataset","text":"<p>               Bases: <code>VisionDataset</code></p> <p>Downsampled ImageNet 32x32 Dataset.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32Dataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index</p> required <p>Returns:     tuple: (image, target) where target is index of the target class.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32DataModule","title":"ImageNet32DataModule","text":"<p>               Bases: <code>VisionDataModule</code></p> <p>TODO: Add a <code>val_split</code> argument, that supports a value of <code>0</code>.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32DataModule.prepare_data","title":"prepare_data","text":"<pre><code>prepare_data() -&gt; None\n</code></pre> <p>Saves files to data_dir.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32DataModule.default_transforms","title":"default_transforms","text":"<pre><code>default_transforms() -&gt; Callable\n</code></pre> <p>Default transform for the dataset.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32DataModule.train_dataloader","title":"train_dataloader","text":"<pre><code>train_dataloader() -&gt; DataLoader\n</code></pre> <p>The train dataloader.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32DataModule.val_dataloader","title":"val_dataloader","text":"<pre><code>val_dataloader() -&gt; DataLoader\n</code></pre> <p>The val dataloader.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.ImageNet32DataModule.test_dataloader","title":"test_dataloader","text":"<pre><code>test_dataloader() -&gt; DataLoader\n</code></pre> <p>The test dataloader.</p>"},{"location":"reference/project/datamodules/image_classification/imagenet32/#project.datamodules.image_classification.imagenet32.get_train_val_indices","title":"get_train_val_indices","text":"<pre><code>get_train_val_indices(\n    dataset_labels: Sequence[int] | ndarray,\n    nb_imgs_in_val: int,\n    split_seed: int,\n) -&gt; tuple[list[int], list[int]]\n</code></pre> <p>Keeps the first <code>nb_imgs_in_val</code> images of each class in the validation set.</p>"},{"location":"reference/project/datamodules/image_classification/inaturalist/","title":"Inaturalist","text":""},{"location":"reference/project/datamodules/image_classification/inaturalist/#project.datamodules.image_classification.inaturalist.INaturalistDataModule","title":"INaturalistDataModule","text":"<p>               Bases: <code>ImageClassificationDataModule</code></p>"},{"location":"reference/project/datamodules/image_classification/inaturalist/#project.datamodules.image_classification.inaturalist.INaturalistDataModule.name","title":"name  <code>class-attribute</code>","text":"<pre><code>name: str = 'inaturalist'\n</code></pre> <p>Dataset name.</p>"},{"location":"reference/project/datamodules/image_classification/inaturalist/#project.datamodules.image_classification.inaturalist.INaturalistDataModule.dataset_cls","title":"dataset_cls  <code>class-attribute</code>","text":"<pre><code>dataset_cls: type[INaturalist] = INaturalist\n</code></pre> <p>Dataset class to use.</p>"},{"location":"reference/project/datamodules/image_classification/inaturalist/#project.datamodules.image_classification.inaturalist.INaturalistDataModule.dims","title":"dims  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dims: tuple[C, H, W] = (C(3), H(224), W(224))\n</code></pre> <p>A tuple describing the shape of the data.</p>"},{"location":"reference/project/datamodules/image_classification/inaturalist/#project.datamodules.image_classification.inaturalist.INaturalistDataModule.default_transforms","title":"default_transforms","text":"<pre><code>default_transforms() -&gt; Callable\n</code></pre> <p>Default transform for the dataset.</p>"},{"location":"reference/project/datamodules/image_classification/mnist/","title":"Mnist","text":""},{"location":"reference/project/datamodules/image_classification/mnist/#project.datamodules.image_classification.mnist.MNISTDataModule","title":"MNISTDataModule","text":"<p>               Bases: <code>ImageClassificationDataModule</code></p> <p>.. figure:: https://miro.medium.com/max/744/1*AO2rIhzRYzFVQlFLx9DM9A.png     :width: 400     :alt: MNIST</p> Specs <ul> <li>10 classes (1 per digit)</li> <li>Each image is (1 x 28 x 28)</li> </ul> <p>Standard MNIST, train, val, test splits and transforms</p> <p>Transforms::</p> <pre><code>mnist_transforms = transform_lib.Compose([\n    transform_lib.ToTensor()\n])\n</code></pre> <p>Example::</p> <pre><code>from pl_bolts.datamodules import MNISTDataModule\n\ndm = MNISTDataModule('.')\nmodel = LitModel()\n\nTrainer().fit(model, datamodule=dm)\n</code></pre>"},{"location":"reference/project/datamodules/image_classification/mnist/#project.datamodules.image_classification.mnist.MNISTDataModule.__init__","title":"__init__","text":"<pre><code>__init__(\n    data_dir: str | None = None,\n    val_split: int | float = 0.2,\n    num_workers: int | None = 0,\n    normalize: bool = False,\n    batch_size: int = 32,\n    seed: int = 42,\n    shuffle: bool = True,\n    pin_memory: bool = True,\n    drop_last: bool = False,\n    *args: Any,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str | None</code> <p>Where to save/load the data</p> <code>None</code> <code>val_split</code> <code>int | float</code> <p>Percent (float) or number (int) of samples to use for the validation split</p> <code>0.2</code> <code>num_workers</code> <code>int | None</code> <p>How many workers to use for loading data</p> <code>0</code> <code>normalize</code> <code>bool</code> <p>If true applies image normalize</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>How many samples per batch to load</p> <code>32</code> <code>seed</code> <code>int</code> <p>Random seed to be used for train/val/test splits</p> <code>42</code> <code>shuffle</code> <code>bool</code> <p>If true shuffles the train data every epoch</p> <code>True</code> <code>pin_memory</code> <code>bool</code> <p>If true, the data loader will copy Tensors into CUDA pinned memory before         returning them</p> <code>True</code> <code>drop_last</code> <code>bool</code> <p>If true drops the last incomplete batch</p> <code>False</code>"},{"location":"reference/project/networks/fcnet/","title":"Fcnet","text":"<p>An example of a simple fully connected network.</p>"},{"location":"reference/project/networks/fcnet/#project.networks.fcnet.FcNet","title":"FcNet","text":"<p>               Bases: <code>Sequential</code></p>"},{"location":"reference/project/networks/fcnet/#project.networks.fcnet.FcNet.HParams","title":"HParams","text":"<p>Dataclass containing the network hyper-parameters.</p>"},{"location":"reference/project/networks/fcnet/#project.networks.fcnet.FcNet.HParams.dropout_rate","title":"dropout_rate  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dropout_rate: FloatBetween0And1 = 0.5\n</code></pre> <p>Dropout rate.</p> <p>Set to 0 to disable dropout.</p>"},{"location":"reference/project/networks/layers/layers/","title":"Layers","text":"<p>Simple layers you might find useful when creating new networks.</p>"},{"location":"reference/project/networks/layers/layers/#project.networks.layers.layers.Lambda","title":"Lambda","text":"<p>               Bases: <code>Module</code>, <code>Module[..., OutT]</code></p> <p>A simple nn.Module wrapping a function.</p> <p>Any positional or keyword arguments passed to the constructor are saved into a <code>args</code> and <code>kwargs</code> attribute. During the forward pass, these arguments are then bound to the function <code>f</code> using a <code>functools.partial</code>. Any additional arguments to the <code>forward</code> method are then passed to the partial.</p>"},{"location":"reference/project/networks/layers/layers/#project.networks.layers.layers.Branch","title":"Branch","text":"<p>               Bases: <code>Module</code>, <code>Module[P, dict[str, T]]</code></p> <p>Module that executes each branch and returns a dictionary with the results of each.</p>"},{"location":"reference/project/networks/layers/layers/#project.networks.layers.layers.Merge","title":"Merge","text":"<p>               Bases: <code>Module</code>, <code>Module[[tuple[Tensor, ...] | dict[str, Tensor]], OutT]</code></p> <p>Unpacks the output of the previous block (Branch) before it is fed to the wrapped module.</p>"},{"location":"reference/project/networks/layers/layers/#project.networks.layers.layers.Merge.__init__","title":"__init__","text":"<pre><code>__init__(f: Module[..., OutT]) -&gt; None\n</code></pre> <p>Unpacks the output of a previous block before it is fed to <code>f</code>.</p>"},{"location":"reference/project/networks/layers/layers/#project.networks.layers.layers.Sample","title":"Sample","text":"<p>               Bases: <code>Lambda</code>, <code>Module[[Distribution], Tensor]</code></p> <p>Layer that samples from a distribution.</p>"},{"location":"reference/project/networks/layers/sequential/","title":"Sequential","text":""},{"location":"reference/project/utils/device/","title":"Device","text":""},{"location":"reference/project/utils/device/#project.utils.device.default_device","title":"default_device","text":"<pre><code>default_device() -&gt; device\n</code></pre> <p>Returns the default device (GPU if available, else CPU).</p>"},{"location":"reference/project/utils/env_vars/","title":"Env vars","text":""},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.SLURM_JOB_ID","title":"SLURM_JOB_ID  <code>module-attribute</code>","text":"<pre><code>SLURM_JOB_ID: int | None = (\n    int(environ[\"SLURM_JOB_ID\"])\n    if \"SLURM_JOB_ID\" in environ\n    else None\n)\n</code></pre> <p>The value of the 'SLURM_JOB_ID' environment variable.</p> <p>See https://slurm.schedmd.com/sbatch.html#OPT_SLURM_JOB_ID.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.SLURM_TMPDIR","title":"SLURM_TMPDIR  <code>module-attribute</code>","text":"<pre><code>SLURM_TMPDIR: Path | None = (\n    Path(environ[\"SLURM_TMPDIR\"])\n    if \"SLURM_TMPDIR\" in environ\n    else (\n        tmp\n        if SLURM_JOB_ID is not None and exists()\n        else None\n    )\n)\n</code></pre> <p>The SLURM temporary directory, the fastest storage available.</p> <ul> <li>Extract your dataset to this directory at the start of your job.</li> <li>Remember to move any files created here to $SCRATCH since everything gets deleted at the end of the job.</li> </ul> <p>See https://docs.mila.quebec/Information.html#slurm-tmpdir for more information.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.SCRATCH","title":"SCRATCH  <code>module-attribute</code>","text":"<pre><code>SCRATCH = (\n    Path(environ[\"SCRATCH\"])\n    if \"SCRATCH\" in environ\n    else None\n)\n</code></pre> <p>Network directory where temporary logs / checkpoints / custom datasets should be saved.</p> <p>Note that this is temporary storage. Files that you wish to be saved long-term should be saved to the <code>ARCHIVE</code> directory.</p> <p>See https://docs.mila.quebec/Information.html#scratch for more information.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.ARCHIVE","title":"ARCHIVE  <code>module-attribute</code>","text":"<pre><code>ARCHIVE = (\n    Path(environ[\"ARCHIVE\"])\n    if \"ARCHIVE\" in environ\n    else None\n)\n</code></pre> <p>Network directory for long-term storage. Only accessible from the login or cpu-only compute nodes.</p> <p>See https://docs.mila.quebec/Information.html#archive for more information.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.NETWORK_DIR","title":"NETWORK_DIR  <code>module-attribute</code>","text":"<pre><code>NETWORK_DIR = (\n    Path(environ[\"NETWORK_DIR\"])\n    if \"NETWORK_DIR\" in environ\n    else _network_dir if exists() else None\n)\n</code></pre> <p>The (read-only) network directory that contains datasets/weights/etc.</p> <p>todo: adapt this for the DRAC clusters.</p> <p>When running outside of the mila/DRAC clusters, this will be <code>None</code>, but can be mocked by setting the <code>NETWORK_DIR</code> environment variable.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.REPO_ROOTDIR","title":"REPO_ROOTDIR  <code>module-attribute</code>","text":"<pre><code>REPO_ROOTDIR = parent\n</code></pre> <p>The root directory of this repository on this machine.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.DATA_DIR","title":"DATA_DIR  <code>module-attribute</code>","text":"<pre><code>DATA_DIR = Path(\n    get(\n        \"DATA_DIR\",\n        SLURM_TMPDIR or SCRATCH or REPO_ROOTDIR / \"data\",\n    )\n)\n</code></pre> <p>Local Directory where datasets should be extracted on this machine.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.NUM_WORKERS","title":"NUM_WORKERS  <code>module-attribute</code>","text":"<pre><code>NUM_WORKERS = int(\n    get(\n        \"SLURM_CPUS_PER_TASK\",\n        get(\n            \"SLURM_CPUS_ON_NODE\",\n            (\n                len(sched_getaffinity(0))\n                if hasattr(os, \"sched_getaffinity\")\n                else cpu_count()\n            ),\n        ),\n    )\n)\n</code></pre> <p>Default number of workers to be used by dataloaders, based on the number of CPUs and/or tasks.</p>"},{"location":"reference/project/utils/env_vars/#project.utils.env_vars.get_constant","title":"get_constant","text":"<pre><code>get_constant(name: str)\n</code></pre> <p>Resolver for Hydra to get the value of a constant in this file.</p>"},{"location":"reference/project/utils/hydra_config_utils/","title":"Hydra config utils","text":""},{"location":"reference/project/utils/hydra_config_utils/#project.utils.hydra_config_utils.get_target_of_config","title":"get_target_of_config","text":"<pre><code>get_target_of_config(\n    config_group: str,\n    config_name: str,\n    _cs: ConfigStore | None = None,\n) -&gt; Callable\n</code></pre> <p>Returns the class that is to be instantiated by the given config name.</p> <p>In the case of inner dataclasses (e.g. Model.HParams), this returns the outer class (Model).</p>"},{"location":"reference/project/utils/hydra_config_utils/#project.utils.hydra_config_utils.import_object","title":"import_object","text":"<pre><code>import_object(target_path: str)\n</code></pre> <p>Imports the object at the given path.</p>"},{"location":"reference/project/utils/hydra_config_utils/#project.utils.hydra_config_utils.import_object--examples","title":"Examples","text":"<pre><code>assert False\n</code></pre>"},{"location":"reference/project/utils/hydra_config_utils/#project.utils.hydra_config_utils.get_all_configs_in_group_of_type","title":"get_all_configs_in_group_of_type","text":"<pre><code>get_all_configs_in_group_of_type(\n    group_name: str,\n    config_target_type: type | tuple[type, ...],\n    include_subclasses: bool = True,\n) -&gt; list[str]\n</code></pre> <p>Returns the names of all the configs in the given config group that have this target or a subclass of it.</p>"},{"location":"reference/project/utils/hydra_config_utils/#project.utils.hydra_config_utils.get_all_configs_in_group_with_target","title":"get_all_configs_in_group_with_target","text":"<pre><code>get_all_configs_in_group_with_target(\n    group_name: str, some_type: type\n) -&gt; list[str]\n</code></pre> <p>Retrieves the names of all the configs in the given group that are used to construct objects of the given type.</p>"},{"location":"reference/project/utils/hydra_utils/","title":"Hydra utils","text":"<p>Utility functions related to working with Hydra.</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.patched_safe_name","title":"patched_safe_name","text":"<pre><code>patched_safe_name(obj: Any, repr_allowed: bool = True)\n</code></pre> <p>Patches a bug in Hydra-zen where the target of inner classes is incorrect: https://github.com/mit-ll-responsible-ai/hydra-zen/issues/705</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.interpolate_config_attribute","title":"interpolate_config_attribute","text":"<pre><code>interpolate_config_attribute(\n    *attributes: str,\n    default: Any | Literal[MISSING] = MISSING\n)\n</code></pre> <p>Use this in a config to to get an attribute from another config after it is instantiated.</p> <p>Multiple attributes can be specified, which will lead to trying each of them in order until the attribute is found. If none are found, then an error will be raised.</p> <p>For example, if we only know the number of classes in the datamodule after it is instantiated, we can set this in the network config so it is created with the right number of output dims.</p> <pre><code>_target_: torchvision.models.resnet50\nnum_classes: ${instance_attr:datamodule.num_classes}\n</code></pre> <p>This is equivalent to:</p> <p>import hydra_zen import torchvision.models resnet50_config = hydra_zen.builds( ...     torchvision.models.resnet50, ...     num_classes=interpolate_config_attribute(\"datamodule.num_classes\"), ...     populate_full_signature=True, ... ) print(hydra_zen.to_yaml(resnet50_config))  # doctest: +NORMALIZE_WHITESPACE target: torchvision.models.resnet.resnet50 weights: null progress: true num_classes: ${instance_attr:datamodule.num_classes}</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.interpolated_field","title":"interpolated_field","text":"<pre><code>interpolated_field(\n    interpolation: str,\n    default: T | Literal[MISSING] = MISSING,\n    default_factory: (\n        Callable[[], T] | Literal[MISSING]\n    ) = MISSING,\n    instance_attr: bool = False,\n) -&gt; T\n</code></pre> <p>Field with a default value computed with a OmegaConf-style interpolation when appropriate.</p> <p>When the dataclass is created by Hydra / OmegaConf, the interpolation is used. Otherwise, behaves as usual (either using default or calling the default_factory).</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.interpolated_field--parameters","title":"Parameters","text":"<p>interpolation: The string interpolation to use to get the default value. default: The default value to use when not in a hydra/OmegaConf context. default_factory: The default value to use when not in a hydra/OmegaConf context. instance_attr: Whether to use the <code>instance_attr</code> custom resolver to run the interpolation         with respect to instantiated objects instead of their configs.     Passing <code>interpolation='${instance_attr:some_config.some_attr}'</code> has the same effect.</p> <p>This last parameter is important, since in order to retrieve the instance attribute, we need to instantiate the objects, which could be expensive. These instantiated objects are reused at least, but still, be mindful when using this parameter.</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.add_attributes","title":"add_attributes","text":"<pre><code>add_attributes(fn: partial[T]) -&gt; Partial[T]\n</code></pre> <p>Adds a getattr to the partial that returns the value in <code>v.keywords</code>.</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.get_instantiated_attr","title":"get_instantiated_attr","text":"<pre><code>get_instantiated_attr(\n    *attributes: str,\n    _instantiated_objects_cache: (\n        MutableMapping[str, Any] | None\n    ) = None\n)\n</code></pre> <p>Quite hacky: Allows interpolations to get the value of the objects, rather than configs.</p>"},{"location":"reference/project/utils/hydra_utils/#project.utils.hydra_utils.make_config_and_store","title":"make_config_and_store","text":"<pre><code>make_config_and_store(\n    target: Callable[..., Target],\n    *,\n    store: ZenStore,\n    **overrides\n)\n</code></pre> <p>Creates a config dataclass for the given target and stores it in the config store.</p> <p>This uses hydra_zen.builds to create the config dataclass and stores it at the name <code>config_name</code>, or <code>target.__name__</code>.</p>"},{"location":"reference/project/utils/testutils/","title":"Testutils","text":"<p>Utility functions useful for testing.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.default_marks_for_config_name","title":"default_marks_for_config_name  <code>module-attribute</code>","text":"<pre><code>default_marks_for_config_name: dict[\n    str, list[MarkDecorator]\n] = {\n    \"imagenet32\": [slow],\n    \"inaturalist\": [\n        slow,\n        skipif(\n            not NETWORK_DIR and exists(),\n            reason=\"Expects to be run on the Mila cluster for now\",\n        ),\n    ],\n    \"imagenet\": [\n        slow,\n        skipif(\n            not NETWORK_DIR and exists(),\n            reason=\"Expects to be run on a cluster with the ImageNet dataset.\",\n        ),\n    ],\n    \"vision\": [\n        skip(\n            reason=\"Base class, shouldn't be instantiated.\"\n        )\n    ],\n}\n</code></pre> <p>Dict with some default marks for some configs name.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.ParametrizedFixture","title":"ParametrizedFixture","text":"<p>Small helper function that creates a parametrized pytest fixture for the given values.</p> <p>The name of the fixture will be the name that is used for this variable on a class.</p> <p>For example:</p> <pre><code>class TestFoo:\n    odd = ParametrizedFixture([True, False])\n\n    def test_something(self, odd: bool):\n        '''some kind of test that uses odd'''\n\n    # NOTE: This fixture can also be used by other fixtures:\n\n    @pytest.fixture\n    def some_number(self, odd: bool):\n        return 1 if odd else 2\n\n    def test_foo(self, some_number: int):\n        '''some kind of test that uses some_number'''\n</code></pre>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.RngState","title":"RngState  <code>dataclass</code>","text":""},{"location":"reference/project/utils/testutils/#project.utils.testutils.RngState.get","title":"get  <code>classmethod</code>","text":"<pre><code>get()\n</code></pre> <p>Gets the state of the random/numpy/torch random number generators.</p> <p>Note: do a deepcopy just in case the libraries return the rng state \"by reference\" and keep modifying it.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.RngState.set","title":"set","text":"<pre><code>set()\n</code></pre> <p>Resets the state of the random/numpy/torch random number generators with the contents of <code>self</code>.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.parametrized_fixture","title":"parametrized_fixture","text":"<pre><code>parametrized_fixture(\n    name: str, values: Sequence, ids=None, **kwargs\n)\n</code></pre> <p>Small helper function that creates a parametrized pytest fixture for the given values.</p> <p>NOTE: When writing a fixture in a test class, use <code>ParametrizedFixture</code> instead.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.run_for_all_datamodules","title":"run_for_all_datamodules","text":"<pre><code>run_for_all_datamodules(\n    datamodule_names: list[str] | None = None,\n    datamodule_name_to_marks: (\n        dict[str, MarkDecorator | list[MarkDecorator]]\n        | None\n    ) = None,\n)\n</code></pre> <p>Apply this marker to a test to make it run with all available datasets (datamodules).</p> <p>The test should use the <code>datamodule</code> fixture, either as an input argument to the test function or indirectly by using a fixture that depends on the <code>datamodule</code> fixture.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.run_for_all_datamodules--parameters","title":"Parameters","text":"<p>datamodule_names: List of datamodule names to use for tests.         By default, lists out the generic datamodules (the datamodules that aren't specific to a     single algorithm, for example the InfGendatamodules of WakeSleep.)</p> <p>datamodule_to_marks: Dictionary from datamodule names to pytest marks (e.g.         <code>pytest.mark.xfail</code>, <code>pytest.mark.skip</code>) to use for that particular datamodule.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.run_for_all_configs_of_type","title":"run_for_all_configs_of_type","text":"<pre><code>run_for_all_configs_of_type(\n    config_group: str, config_target_type: type\n)\n</code></pre> <p>Parametrizes a test to run with all the configs in the given group that have targets which are subclasses of the given type.</p> <p>For example:</p> <pre><code>@run_for_all_subclasses_of(\"network\", torch.nn.Module)\ndef test_something_about_the_network(network: torch.nn.Module):\n    ''' This test will run with all the configs in the 'network' group that produce nn.Modules! '''\n</code></pre>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.parametrize_when_used","title":"parametrize_when_used","text":"<pre><code>parametrize_when_used(\n    arg_name_or_fixture: str | Callable,\n    values: list,\n    indirect: bool | None = None,\n) -&gt; MarkDecorator\n</code></pre> <p>Fixture that applies <code>pytest.mark.parametrize</code> only when the argument is used (directly or indirectly).</p> <p>When <code>pytest.mark.parametrize</code> is applied to a class, all test methods in that class need to use the parametrized argument, otherwise an error is raised. This function exists to work around this and allows writing test methods that don't use the parametrized argument.</p> <p>For example, this works, but would not be possible with <code>pytest.mark.parametrize</code>:</p> <pre><code>import pytest\n\n@parametrize_when_used(\"value\", [1, 2, 3])\nclass TestFoo:\n    def test_foo(self, value):\n        ...\n\n    def test_bar(self, value):\n        ...\n\n    def test_something_else(self):  # This will cause an error!\n        pass\n</code></pre>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.parametrize_when_used--parameters","title":"Parameters","text":"<p>arg_name_or_fixture: The name of the argument to parametrize, or a fixture to parametrize         indirectly. values: The values to be used to parametrize the test.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.parametrize_when_used--returns","title":"Returns","text":"<p>A <code>pytest.MarkDecorator</code> that parametrizes the test with the given values only when the argument is used (directly or indirectly) by the test.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.run_for_all_configs_in_group","title":"run_for_all_configs_in_group","text":"<pre><code>run_for_all_configs_in_group(\n    group_name: str,\n    config_name_to_marks: (\n        Mapping[str, MarkDecorator | list[MarkDecorator]]\n        | None\n    ) = None,\n)\n</code></pre> <p>Apply this marker to a test to make it run with all configs in a given group.</p> <p>This assumes that a \"<code>group_name</code>_config\" fixture is defined, for example, <code>algorithm_config</code>, <code>datamodule_config</code>, <code>network_config</code>. This then does an indirect parametrization of that fixture, so that it receives the config name as a parameter and returns it.</p> <p>The test wrapped test will uses all config from that group if they are used either as an input argument to the test function or if it the input argument to a fixture function.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.run_for_all_configs_in_group--parameters","title":"Parameters","text":"<p>datamodule_names: List of datamodule names to use for tests.         By default, lists out the generic datamodules (the datamodules that aren't specific to a     single algorithm, for example the InfGendatamodules of WakeSleep.)</p> <p>datamodule_to_marks: Dictionary from datamodule names to pytest marks (e.g.         <code>pytest.mark.xfail</code>, <code>pytest.mark.skip</code>) to use for that particular datamodule.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.fork_rng","title":"fork_rng","text":"<pre><code>fork_rng()\n</code></pre> <p>Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in.</p>"},{"location":"reference/project/utils/testutils/#project.utils.testutils.seeded_rng","title":"seeded_rng","text":"<pre><code>seeded_rng(seed: int = 42)\n</code></pre> <p>Forks the RNG and seeds the torch, numpy, and random RNGs while inside the block.</p>"},{"location":"reference/project/utils/utils/","title":"Utils","text":""},{"location":"reference/project/utils/utils/#project.utils.utils.log_once","title":"log_once  <code>cached</code>","text":"<pre><code>log_once(message: str, level: int) -&gt; None\n</code></pre> <p>Logs a message once. The message is logged at the specified level.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to log.</p> required <code>level</code> <code>int</code> <p>The logging level to use.</p> required"},{"location":"reference/project/utils/utils/#project.utils.utils.get_log_dir","title":"get_log_dir","text":"<pre><code>get_log_dir(trainer: Trainer | None) -&gt; Path\n</code></pre> <p>Gives back the default directory to use when <code>trainer.log_dir</code> is None (no logger used).</p>"},{"location":"reference/project/utils/utils/#project.utils.utils.validate_datamodule","title":"validate_datamodule","text":"<pre><code>validate_datamodule(datamodule: DM) -&gt; DM\n</code></pre> <p>Checks that the transforms / things are setup correctly.</p> <p>Returns the same datamodule.</p>"},{"location":"reference/project/utils/utils/#project.utils.utils.print_config","title":"print_config","text":"<pre><code>print_config(\n    config: DictConfig,\n    print_order: Sequence[str] = (\n        \"algorithm\",\n        \"network\",\n        \"datamodule\",\n        \"trainer\",\n    ),\n    resolve: bool = True,\n) -&gt; None\n</code></pre> <p>Prints content of DictConfig using Rich library and its tree structure.</p> <p>TAKEN FROM https://github.com/ashleve/lightning-hydra-template/blob/6a92395ed6afd573fa44dd3a054a603acbdcac06/src/utils/__init__.py#L56</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>DictConfig</code> <p>Configuration composed by Hydra.</p> required <code>print_order</code> <code>Sequence[str]</code> <p>Determines in what order config components are printed.</p> <code>('algorithm', 'network', 'datamodule', 'trainer')</code> <code>resolve</code> <code>bool</code> <p>Whether to resolve reference fields of DictConfig.</p> <code>True</code>"},{"location":"reference/project/utils/types/protocols/","title":"Protocols","text":""},{"location":"reference/project/utils/types/protocols/#project.utils.types.protocols.DataModule","title":"DataModule","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol that shows the minimal attributes / methods of the <code>LightningDataModule</code> class.</p> <p>This is used to type hint the batches that are yielded by the DataLoaders.</p>"}]}